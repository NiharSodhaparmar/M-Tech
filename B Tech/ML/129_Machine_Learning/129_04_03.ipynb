{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wk3R5JNLHbKr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "adJRd8_pH31f",
    "outputId": "46a86d42-1503-4ddc-ef6f-4c3efeba6983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data :\n",
      "        v1                                                 v2\n",
      "0    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "1    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "2    spam  WINNER!! As a valued network customer you have...\n",
      "3    spam  Had your mobile 11 months or more? U R entitle...\n",
      "4    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "..    ...                                                ...\n",
      "508  spam  This is the 2nd time we have tried 2 contact u...\n",
      "509   ham              Will ï¿½_ b going to esplanade fr home?\n",
      "510   ham  Pity, * was in mood for that. So...any other s...\n",
      "511   ham  The guy did some bitching but I acted like i'd...\n",
      "512   ham                         Rofl. Its true to its name\n",
      "\n",
      "[513 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 513 entries, 0 to 512\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      513 non-null    object\n",
      " 1   v2      513 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.1+ KB\n",
      "\n",
      "Data statistics\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "datasets = pd.read_csv('/home/nihar/Desktop/SEM 7/ML/Lab/Lab4/spam1.csv') \n",
    "print(\"\\nData :\\n\",datasets)\n",
    "print(\"\\nData statistics\\n\",datasets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AWKnWaKUIJRJ",
    "outputId": "7fd963ba-c488-4d51-abb2-0db98fc2028f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410,) (103,)\n",
      "(410,) (103,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,Y = datasets['v2'],datasets['v1']\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.20,random_state=129)\n",
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "YjqJEij0IrZA",
    "outputId": "eded44ba-8d82-4a0d-fcc9-36e22676cdd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 5345) (103, 5345)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(lowercase=True,stop_words=stopwords,ngram_range=(1,2))\n",
    "xtrain = cv.fit_transform(x_train).toarray()\n",
    "xtest = cv.transform(x_test).toarray()\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "GqbXuL1dI2wN",
    "outputId": "2c74e56b-c915-4f10-88e7-e5b4ae3e59ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.970873786407767\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        65\n",
      "           1       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.97       103\n",
      "   macro avg       0.97      0.97      0.97       103\n",
      "weighted avg       0.97      0.97      0.97       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain,y_train)\n",
    "ypred = mnb.predict(xtest)\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_test,ypred))\n",
    "print(\"classification report:\\n\", metrics.classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "hWkM2unVJCiE",
    "outputId": "0113c370-be87-4c48-b4d4-c51234515c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 5345) (103, 5345)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nihar/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer(lowercase=True,stop_words=stopwords,ngram_range=(1,2))\n",
    "xtrain = cv.fit_transform(x_train).toarray()\n",
    "xtest = cv.transform(x_test).toarray()\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "Oww2N7lUJQ_R",
    "outputId": "eca46ea4-ffca-4c7a-dadc-501ed95180a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9029126213592233\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        65\n",
      "           1       1.00      0.74      0.85        38\n",
      "\n",
      "    accuracy                           0.90       103\n",
      "   macro avg       0.93      0.87      0.89       103\n",
      "weighted avg       0.92      0.90      0.90       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain,y_train)\n",
    "ypred = mnb.predict(xtest)\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_test,ypred))\n",
    "print(\"classification report:\\n\", metrics.classification_report(y_test,ypred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "129_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
